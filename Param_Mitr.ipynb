{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model With GPU (Fine tuning the model using LoRA)","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset, load_from_disk\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer, GenerationConfig\nimport torch\nfrom peft import LoraConfig, TaskType, get_peft_model, PeftModel, PeftConfig\nfrom tqdm import tqdm\nimport evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:34:26.297650Z","iopub.execute_input":"2025-04-09T07:34:26.297989Z","iopub.status.idle":"2025-04-09T07:34:26.302113Z","shell.execute_reply.started":"2025-04-09T07:34:26.297931Z","shell.execute_reply":"2025-04-09T07:34:26.301325Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## Import the data from Hugging face","metadata":{"execution":{"iopub.status.busy":"2025-04-09T06:53:56.303114Z","iopub.execute_input":"2025-04-09T06:53:56.303419Z","iopub.status.idle":"2025-04-09T06:53:56.307613Z","shell.execute_reply.started":"2025-04-09T06:53:56.303386Z","shell.execute_reply":"2025-04-09T06:53:56.306607Z"}}},{"cell_type":"code","source":"# dataset = load_dataset('samhog/psychology-10k', split = ['train'])[0]\n# dataset.save_to_disk('./dataset')\n\ndataset = load_from_disk('./dataset')\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:39.149315Z","iopub.execute_input":"2025-04-09T07:08:39.149667Z","iopub.status.idle":"2025-04-09T07:08:39.277850Z","shell.execute_reply.started":"2025-04-09T07:08:39.149630Z","shell.execute_reply":"2025-04-09T07:08:39.276859Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction'],\n    num_rows: 9846\n})"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"let's walk trough the data","metadata":{}},{"cell_type":"code","source":"def print_conv(me, model):\n    for i, j in zip(me, model):\n        print(\n            f\"\"\"\nMe : {i}\n\nParam mitr : {j}\\n\\n\n            \"\"\"\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:39.279354Z","iopub.execute_input":"2025-04-09T07:08:39.279646Z","iopub.status.idle":"2025-04-09T07:08:39.283348Z","shell.execute_reply.started":"2025-04-09T07:08:39.279618Z","shell.execute_reply":"2025-04-09T07:08:39.282456Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"print_conv(dataset['input'][:3], dataset['output'][:3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:39.284573Z","iopub.execute_input":"2025-04-09T07:08:39.284760Z","iopub.status.idle":"2025-04-09T07:08:39.323901Z","shell.execute_reply.started":"2025-04-09T07:08:39.284744Z","shell.execute_reply":"2025-04-09T07:08:39.323108Z"}},"outputs":[{"name":"stdout","text":"\nMe : I'm feeling really anxious lately and I don't know why.\n\nParam mitr : It's common to feel anxious at times, and there can be many reasons for it. Have there been any recent changes or stressors in your life that may be contributing to your anxiety? Let's work together to identify any triggers and develop coping strategies to manage your anxiety.\n\n\n            \n\nMe : I think my partner may be cheating on me. What should I do?\n\nParam mitr : It's understandable to feel worried and suspicious in this situation. Have you talked to your partner about your concerns? It's important to communicate openly and honestly with them. If you're still feeling uncertain, we can work on developing a plan to address the situation in a healthy and constructive way.\n\n\n            \n\nMe : I'm feeling really overwhelmed with work and school. I don't know how to manage my time and it's causing me a lot of stress.\n\nParam mitr : It sounds like you're going through a difficult time. Let's work on creating a schedule that prioritizes your tasks and allows for breaks throughout the day. We can also discuss some stress management techniques to help you cope with the pressure.\n\n\n            \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"dataset.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:39.324747Z","iopub.execute_input":"2025-04-09T07:08:39.325066Z","iopub.status.idle":"2025-04-09T07:08:39.330503Z","shell.execute_reply.started":"2025-04-09T07:08:39.325036Z","shell.execute_reply":"2025-04-09T07:08:39.329657Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(9846, 3)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"Dataset = dataset.train_test_split(test_size = 0.2)\nDataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:39.331385Z","iopub.execute_input":"2025-04-09T07:08:39.331685Z","iopub.status.idle":"2025-04-09T07:08:39.358539Z","shell.execute_reply.started":"2025-04-09T07:08:39.331655Z","shell.execute_reply":"2025-04-09T07:08:39.357731Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input', 'output', 'instruction'],\n        num_rows: 7876\n    })\n    test: Dataset({\n        features: ['input', 'output', 'instruction'],\n        num_rows: 1970\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Import our model with its tokenizer","metadata":{}},{"cell_type":"code","source":"# if you want to use QLoRA use this but remember in \n# normal inference you have to use GPU\n\n# bnb_config = BitsAndBytesConfig(\n#     load_in_4bit=True,\n#     bnb_4bit_quant_type=\"nf4\",\n#     bnb_4bit_compute_dtype=torch.bfloat16,\n#     bnb_4bit_use_double_quant=True,\n#     bnb_4bit_quant_storage=torch.bfloat16,\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:39.359434Z","iopub.execute_input":"2025-04-09T07:08:39.359717Z","iopub.status.idle":"2025-04-09T07:08:39.363507Z","shell.execute_reply.started":"2025-04-09T07:08:39.359689Z","shell.execute_reply":"2025-04-09T07:08:39.362556Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Importing model from the Hugging Face hub\n\nmodel_name = 'google/flan-t5-small'\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    torch_dtype = torch.bfloat16,\n    # quantization_config = bnb_config # Use it if you want Quantization\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Saving the model\n\n# model.save_pretrained('/kaggle/working/Model')\n# tokenizer.save_pretrained('/kaggle/working/Model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:39.366338Z","iopub.execute_input":"2025-04-09T07:08:39.366532Z","iopub.status.idle":"2025-04-09T07:08:43.733921Z","shell.execute_reply.started":"2025-04-09T07:08:39.366515Z","shell.execute_reply":"2025-04-09T07:08:43.733234Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf354e038f314950823b2b7d4a8db254"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f172faec670c427aad8d486dfef49d54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3dee8c6afb244beb1c59f36493cf951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bb2bf7685bc4075bce5017332fbdf8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ee8ce87e7f44720b78982001823d997"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"862a5e9bbc4e49058909d816b8390c0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"599e3a86ca8b4085a01f91c741f1dd1d"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"Let's try some stuff with tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer(\"hey\", return_token_type_ids = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:43.736163Z","iopub.execute_input":"2025-04-09T07:08:43.736399Z","iopub.status.idle":"2025-04-09T07:08:43.743880Z","shell.execute_reply.started":"2025-04-09T07:08:43.736379Z","shell.execute_reply":"2025-04-09T07:08:43.743208Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [3, 13133, 1], 'attention_mask': [1, 1, 1]}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"device = torch.device('cuda')\ntokenizer.decode(\n    model.generate(\n        tokenizer(\n            dataset['input'][0], return_token_type_ids = False, return_tensors = 'pt', padding=True, truncation=True\n        )['input_ids'].to(device)\n    )[0], skip_special_tokens= True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:43.744643Z","iopub.execute_input":"2025-04-09T07:08:43.744854Z","iopub.status.idle":"2025-04-09T07:08:44.733695Z","shell.execute_reply.started":"2025-04-09T07:08:43.744835Z","shell.execute_reply":"2025-04-09T07:08:44.732825Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\"I'm feeling really anxious lately and I don't know why.\""},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"def inference(input_data, param_mitr = model):\n    intruct = dataset['instruction'][0]\n    task = \"Answer :\"\n    inp = [intruct + \"\\n\" + sent + task for sent in input_data]\n    output = param_mitr.generate(\n        tokenizer(\n            inp, return_token_type_ids = False, return_tensors = 'pt', padding=True, truncation=True\n        )['input_ids'].to(device),\n        generation_config = GenerationConfig(max_new_token = 200)\n    )\n    decoded = [tokenizer.decode(out, skip_special_tokens= True) for out in output]\n    print_conv(input_data, decoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:44.734625Z","iopub.execute_input":"2025-04-09T07:08:44.734851Z","iopub.status.idle":"2025-04-09T07:08:44.739477Z","shell.execute_reply.started":"2025-04-09T07:08:44.734832Z","shell.execute_reply":"2025-04-09T07:08:44.738750Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"inference(dataset['input'][:4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:44.740331Z","iopub.execute_input":"2025-04-09T07:08:44.740523Z","iopub.status.idle":"2025-04-09T07:08:45.085461Z","shell.execute_reply.started":"2025-04-09T07:08:44.740506Z","shell.execute_reply":"2025-04-09T07:08:45.084576Z"}},"outputs":[{"name":"stdout","text":"\nMe : I'm feeling really anxious lately and I don't know why.\n\nParam mitr : I'm feeling very anxious.\n\n\n            \n\nMe : I think my partner may be cheating on me. What should I do?\n\nParam mitr : I should give this patient a call.\n\n\n            \n\nMe : I'm feeling really overwhelmed with work and school. I don't know how to manage my time and it's causing me a lot of stress.\n\nParam mitr : I'm feeling really overwhelmed with work and school. I don't know how to manage my\n\n\n            \n\nMe : I'm having trouble sleeping and I'm constantly tired. I think it might be because of my medication.\n\nParam mitr : I'm having trouble sleeping and I'm constantly tired.\n\n\n            \n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"The model is showing good result on ICL (In Context Learning) with zero shot inference.","metadata":{}},{"cell_type":"code","source":"def tokenize_function(example):\n    intruct = dataset['instruction'][0]\n    task = \"Answer :\"\n    inp = [intruct + \"\\n\" + question + '\\n' + task for question in example['input']]\n    example['input_ids'] = tokenizer(inp, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n    example['labels'] = tokenizer(example['output'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n\n    return example\n\n\ntokenized_datasets = Dataset.map(tokenize_function, batched=True)\ntokenized_datasets = tokenized_datasets.remove_columns(['input', 'output', 'instruction'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:45.086373Z","iopub.execute_input":"2025-04-09T07:08:45.086725Z","iopub.status.idle":"2025-04-09T07:08:50.381174Z","shell.execute_reply.started":"2025-04-09T07:08:45.086686Z","shell.execute_reply":"2025-04-09T07:08:50.380534Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7876 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d22421328934390a7d85b32e83d6b14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1970 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27ab466115e04df294e93c126f265e81"}},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## Fine tune our model (Using LoRA)","metadata":{}},{"cell_type":"code","source":"config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    r = 32,\n    target_modules = \"all-linear\",\n    lora_alpha=32,\n    lora_dropout=0.05\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:50.381983Z","iopub.execute_input":"2025-04-09T07:08:50.382282Z","iopub.status.idle":"2025-04-09T07:08:50.385745Z","shell.execute_reply.started":"2025-04-09T07:08:50.382250Z","shell.execute_reply":"2025-04-09T07:08:50.385014Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"Model = get_peft_model(model, config)\nModel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:50.386535Z","iopub.execute_input":"2025-04-09T07:08:50.386738Z","iopub.status.idle":"2025-04-09T07:08:50.614974Z","shell.execute_reply.started":"2025-04-09T07:08:50.386720Z","shell.execute_reply":"2025-04-09T07:08:50.614201Z"}},"outputs":[{"name":"stdout","text":"trainable params: 5,111,808 || all params: 82,072,960 || trainable%: 6.2284\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"TrainArgs = TrainingArguments(\n    output_dir = './Model',\n    learning_rate = 1e-3,\n    num_train_epochs = 2,\n    per_device_train_batch_size = 4,\n    per_device_eval_batch_size = 4,\n    weight_decay = 0.01,\n    eval_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    logging_steps=1,\n    load_best_model_at_end = True,\n    report_to = ['tensorboard']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:50.615740Z","iopub.execute_input":"2025-04-09T07:08:50.616012Z","iopub.status.idle":"2025-04-09T07:08:50.642346Z","shell.execute_reply.started":"2025-04-09T07:08:50.615990Z","shell.execute_reply":"2025-04-09T07:08:50.641715Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"trainer = Trainer(\n    model = Model,\n    args = TrainArgs,\n    train_dataset = tokenized_datasets['train'],\n    eval_dataset = tokenized_datasets['test']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:50.643073Z","iopub.execute_input":"2025-04-09T07:08:50.643291Z","iopub.status.idle":"2025-04-09T07:08:50.835500Z","shell.execute_reply.started":"2025-04-09T07:08:50.643271Z","shell.execute_reply":"2025-04-09T07:08:50.834799Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import gc\n# To clear the GPU\ndef clean():\n    for i in range(15):\n      gc.collect()\n      torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:50.836234Z","iopub.execute_input":"2025-04-09T07:08:50.836519Z","iopub.status.idle":"2025-04-09T07:08:50.840483Z","shell.execute_reply.started":"2025-04-09T07:08:50.836485Z","shell.execute_reply":"2025-04-09T07:08:50.839497Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"clean()\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:08:50.841297Z","iopub.execute_input":"2025-04-09T07:08:50.841582Z","iopub.status.idle":"2025-04-09T07:30:05.068637Z","shell.execute_reply.started":"2025-04-09T07:08:50.841555Z","shell.execute_reply":"2025-04-09T07:30:05.067815Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3938' max='3938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3938/3938 21:08, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.679700</td>\n      <td>1.628696</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.664100</td>\n      <td>1.618504</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3938, training_loss=1.8223896171914677, metrics={'train_runtime': 1268.6262, 'train_samples_per_second': 12.417, 'train_steps_per_second': 3.104, 'total_flos': 3175508355317760.0, 'train_loss': 1.8223896171914677, 'epoch': 2.0})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"def peft_infrence_with_GPU(input_data, model = Model):\n    intruct = dataset['instruction'][0]\n    task = \"Answer :\"\n    inp = [intruct + \"\\n\" + sent +'\\n'+ task for sent in input_data]\n    output = model.generate(\n        **tokenizer(\n            inp, return_token_type_ids = False, return_tensors = 'pt', padding=True, truncation=True\n        ).to('cuda'),\n        generation_config = GenerationConfig(max_new_tokens=100, num_beams=1)\n    )\n    decoded = [tokenizer.decode(out, skip_special_tokens= True) for out in output]\n    print_conv(input_data, decoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:30:05.069380Z","iopub.execute_input":"2025-04-09T07:30:05.069583Z","iopub.status.idle":"2025-04-09T07:30:05.074230Z","shell.execute_reply.started":"2025-04-09T07:30:05.069564Z","shell.execute_reply":"2025-04-09T07:30:05.073297Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"peft_infrence_with_GPU(Dataset['test']['input'][:4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:30:13.967382Z","iopub.execute_input":"2025-04-09T07:30:13.967666Z","iopub.status.idle":"2025-04-09T07:30:16.115524Z","shell.execute_reply.started":"2025-04-09T07:30:13.967643Z","shell.execute_reply":"2025-04-09T07:30:16.114781Z"}},"outputs":[{"name":"stdout","text":"\nMe : I feel like I'm not good enough compared to my colleagues at work. What can I do to boost my confidence?\n\nParam mitr : It's important to identify your strengths and weaknesses and develop a plan to improve your confidence. Consider seeking professional help from a therapist or a therapist to work through any underlying issues that may be contributing to your lack of confidence. Additionally, practicing self-care and identifying negative self-talk can also help boost confidence.\n\n\n            \n\nMe : I've been feeling really down lately and don't know why. Can you help me figure it out?\n\nParam mitr : It's important to identify the cause of your depression and develop coping strategies to manage it. Let's work on developing coping strategies and identifying any underlying causes that may be contributing to your depression.\n\n\n            \n\nMe : I've been feeling really down and hopeless lately. What can I do to feel better?\n\nParam mitr : It's important to seek professional help to identify the root cause of your depression and develop coping strategies to manage it. It may also be helpful to seek professional help if you're experiencing symptoms of depression.\n\n\n            \n\nMe : I'm feeling really jealous of someone else's success and don't know how to feel better about myself. What can I do to manage my jealousy?\n\nParam mitr : It's important to identify the source of your jealousy and develop coping strategies to manage it. It's also important to identify the source of your jealousy and develop strategies to manage it. It's also important to identify the source of your jealousy and develop strategies to manage it. It's also important to identify the source of your jealousy and develop strategies to manage it.\n\n\n            \n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"model_old = AutoModelForSeq2SeqLM.from_pretrained('/kaggle/working/Model',\n                                              device_map=\"auto\",\n                                              torch_dtype = torch.bfloat16\n                                             )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:51:56.376356Z","iopub.execute_input":"2025-04-09T07:51:56.376678Z","iopub.status.idle":"2025-04-09T07:51:57.008692Z","shell.execute_reply.started":"2025-04-09T07:51:56.376654Z","shell.execute_reply":"2025-04-09T07:51:57.007989Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"def inference(test_data, model_):\n    intruct = dataset['instruction'][0]\n    task = \"Answer :\"\n    inp = [intruct + \"\\n\" + sent +'\\n'+ task for sent in test_data]\n    output = model_.generate(\n        **tokenizer(\n            inp, return_token_type_ids = False, return_tensors = 'pt', padding=True, truncation=True\n        ).to('cuda'),\n        generation_config = GenerationConfig(max_new_tokens=200, num_beams=1)\n    )\n    decoded = [tokenizer.decode(out, skip_special_tokens= True) for out in output]\n    return decoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:50:28.334552Z","iopub.execute_input":"2025-04-09T07:50:28.334868Z","iopub.status.idle":"2025-04-09T07:50:28.339741Z","shell.execute_reply.started":"2025-04-09T07:50:28.334844Z","shell.execute_reply":"2025-04-09T07:50:28.338850Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"rouge = evaluate.load('rouge')\npredicted_new = inference(Dataset['test']['input'][:10], model_ = Model)\npredicted_old = inference(Dataset['test']['input'][:10], model_ = model_old)\nhuman_base_line = Dataset['test']['output'][:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:52:00.436218Z","iopub.execute_input":"2025-04-09T07:52:00.436502Z","iopub.status.idle":"2025-04-09T07:52:03.388357Z","shell.execute_reply.started":"2025-04-09T07:52:00.436480Z","shell.execute_reply":"2025-04-09T07:52:03.387659Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"rouge_score_old = rouge.compute(\n    predictions = predicted_old,\n    references = human_base_line\n)\nrouge_score_old","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:52:05.849053Z","iopub.execute_input":"2025-04-09T07:52:05.849355Z","iopub.status.idle":"2025-04-09T07:52:06.005976Z","shell.execute_reply.started":"2025-04-09T07:52:05.849332Z","shell.execute_reply":"2025-04-09T07:52:06.005228Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.11607087438609179,\n 'rouge2': 0.031482078086114904,\n 'rougeL': 0.0879792724720261,\n 'rougeLsum': 0.08786995168349267}"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"rouge_score_new = rouge.compute(\n    predictions = predicted_new,\n    references = human_base_line\n)\nrouge_score_new","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:52:09.540489Z","iopub.execute_input":"2025-04-09T07:52:09.540768Z","iopub.status.idle":"2025-04-09T07:52:09.709130Z","shell.execute_reply.started":"2025-04-09T07:52:09.540747Z","shell.execute_reply":"2025-04-09T07:52:09.708271Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.42365145391096454,\n 'rouge2': 0.21080558265702876,\n 'rougeL': 0.32149324267318413,\n 'rougeLsum': 0.3200334978676107}"},"metadata":{}}],"execution_count":58},{"cell_type":"markdown","source":"## Save the PEFT Adapter","metadata":{}},{"cell_type":"code","source":"trainer.model.save_pretrained('./peft_for_param_mitr')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:30:22.860978Z","iopub.execute_input":"2025-04-09T07:30:22.861260Z","iopub.status.idle":"2025-04-09T07:30:23.201423Z","shell.execute_reply.started":"2025-04-09T07:30:22.861237Z","shell.execute_reply":"2025-04-09T07:30:23.200337Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Model without GPU (using saved fine-tuned model)","metadata":{}},{"cell_type":"markdown","source":"## Load model from local storage","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('/kaggle/working/Model', device_map=\"auto\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained('/kaggle/working/Model',\n                                              device_map=\"auto\",\n                                              torch_dtype = torch.bfloat16\n                                             )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:30:25.421884Z","iopub.execute_input":"2025-04-09T07:30:25.422194Z","iopub.status.idle":"2025-04-09T07:30:26.142593Z","shell.execute_reply.started":"2025-04-09T07:30:25.422169Z","shell.execute_reply":"2025-04-09T07:30:26.141928Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Load PEFT adapter to the base model","metadata":{}},{"cell_type":"code","source":"peft_model_path = './peft_for_param_mitr'\nModel = PeftModel.from_pretrained(\n            model,\n            peft_model_path,\n            is_trainable = False\n            )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:30:27.924099Z","iopub.execute_input":"2025-04-09T07:30:27.924407Z","iopub.status.idle":"2025-04-09T07:30:28.198143Z","shell.execute_reply.started":"2025-04-09T07:30:27.924381Z","shell.execute_reply":"2025-04-09T07:30:28.197232Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"**These Cell will only work when you do not have GPU**","metadata":{}},{"cell_type":"code","source":"def peft_infrence(input_data, model = Model):\n    intruct = dataset['instruction'][0]\n    task = \"Answer :\"\n    inp = [intruct + \"\\n\" + sent +'\\n'+ task for sent in input_data]\n    output = model.generate(\n        **tokenizer(\n            inp, return_token_type_ids = False, return_tensors = 'pt', padding=True, truncation=True\n        ),\n        generation_config = GenerationConfig(max_new_tokens=200, num_beams=1)\n    )\n    decoded = [tokenizer.decode(out, skip_special_tokens= True) for out in output]\n    print_conv(input_data, decoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:30:29.437296Z","iopub.execute_input":"2025-04-09T07:30:29.437595Z","iopub.status.idle":"2025-04-09T07:30:29.442659Z","shell.execute_reply.started":"2025-04-09T07:30:29.437571Z","shell.execute_reply":"2025-04-09T07:30:29.441666Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# peft_infrence(Dataset['test']['input'][:4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T07:31:25.974776Z","iopub.execute_input":"2025-04-09T07:31:25.975102Z","iopub.status.idle":"2025-04-09T07:31:25.978492Z","shell.execute_reply.started":"2025-04-09T07:31:25.975073Z","shell.execute_reply":"2025-04-09T07:31:25.977566Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}